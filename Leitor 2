import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.cluster import KMeans
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import OneClassSVM
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import xml.etree.ElementTree as ET

# Função para extrair dados de uma nota fiscal em formato XML


def extract_data_from_xml(xml_data):
    root = ET.fromstring(xml_data)
    namespace = {'cte': 'http://www.portalfiscal.inf.br/cte'}

    # Extraindo informações
    data = {
        'CNPJ_Cliente': root.find('.//cte:emit/cte:CNPJ', namespace).text,
        'ValorTotal': float(root.find('.//cte:vPrest/cte:vTPrest', namespace).text),
        'QuantidadeItens': np.random.randint(1, 50),  # Exemplo de itens
        'DataEmissao': root.find('.//cte:ide/cte:dhEmi', namespace).text
    }

    return data


# Dados iniciais
data = {
    'NotaFiscalID': np.arange(1, 101),
    'ValorTotal': np.random.uniform(100, 10000, 100),
    'QuantidadeItens': np.random.randint(1, 50, 100),
    'CNPJ_Cliente': [f'XX.XXX.XXX/{i%10}XXX-XX' for i in range(100)],
    'DataEmissao': pd.date_range(start='2023-01-01', periods=100, freq='D')
}

df = pd.DataFrame(data)

# Mascarando dados sensíveis
df['CNPJ_Cliente'] = df['CNPJ_Cliente'].apply(lambda x: 'XXX.XXX.XXX/XXXX-XX')

# Exemplo de nota fiscal em XML
xml_data = """<?xml version="1.0" encoding="UTF-8" ?>
<cteProc versao="3.00" xmlns="http://www.portalfiscal.inf.br/cte">
    <CTe xmlns="http://www.portalfiscal.inf.br/cte">
        <infCte Id="CTe35231109296295000240570030090307961783251005" versao="3.00">
            <ide>
                <cUF>35</cUF>
                <cCT>78325100</cCT>
                <CFOP>5351</CFOP>
                <natOp>PRESTACAO DE SERVICO AEREO</natOp>
                <mod>57</mod>
                <serie>3</serie>
                <nCT>9030796</nCT>
                <dhEmi>2023-11-02T16:43:38-03:00</dhEmi>
                <tpImp>1</tpImp>
                <tpEmis>1</tpEmis>
                <cDV>5</cDV>
                <tpAmb>1</tpAmb>
                <tpCTe>0</tpCTe>
                <procEmi>0</procEmi>
                <verProc>OnlineApp-1.0</verProc>
                <cMunEnv>3518800</cMunEnv>
                <xMunEnv>GUARULHOS</xMunEnv>
                <UFEnv>SP</UFEnv>
                <modal>02</modal>
                <tpServ>3</tpServ>
                <cMunIni>3518800</cMunIni>
                <xMunIni>GUARULHOS</xMunIni>
                <UFIni>SP</UFIni>
                <cMunFim>3550308</cMunFim>
                <xMunFim>SAO PAULO</xMunFim>
                <UFFim>SP</UFFim>
                <retira>1</retira>
                <indIEToma>1</indIEToma>
            </ide>
            <emit>
                <CNPJ>09296295000240</CNPJ>
                <xNome>AZUL LINHAS AEREAS BRASILEIRAS SA</xNome>
            </emit>
            <receb>
                <CPF>22972180879</CPF>
                <xNome>PEDRO LACAZE</xNome>
            </receb>
            <vPrest>
                <vTPrest>8.59</vTPrest>
            </vPrest>
        </infCte>
    </CTe>
</cteProc>
"""

# Extrair dados da nota fiscal em XML e adicionar ao DataFrame
xml_data_extracted = extract_data_from_xml(xml_data)
# Converter o dicionário para DataFrame
xml_df = pd.DataFrame([xml_data_extracted])
# Usar concat ao invés de append
df = pd.concat([df, xml_df], ignore_index=True)

# Preprocessamento: Removendo colunas não numéricas e escalando os dados
df_cleaned = df.drop(['NotaFiscalID', 'DataEmissao',
                     'CNPJ_Cliente'], axis=1, errors='ignore')
scaler = StandardScaler()
X = scaler.fit_transform(df_cleaned)

# 2. Aplicando métodos de aprendizado não supervisionado

# Método 1: K-Means (Clustering)
kmeans = KMeans(n_clusters=2, random_state=42)
kmeans_labels = kmeans.fit_predict(X)

# Método 2: Isolation Forest (Detecção de Anomalias)
isolation_forest = IsolationForest(contamination=0.1, random_state=42)
iso_forest_labels = isolation_forest.fit_predict(X)


svm = OneClassSVM(nu=0.1, kernel='rbf', gamma=0.1)
svm_labels = svm.fit_predict(X)

# Separando os dados para treino e teste
X_train, X_test, y_train, y_test = train_test_split(
    X, kmeans_labels, test_size=0.2, random_state=42)
decision_tree = DecisionTreeClassifier(random_state=42)
decision_tree.fit(X_train, y_train)
tree_pred = decision_tree.predict(X_test)

# Exibindo os resultados
print(df)
